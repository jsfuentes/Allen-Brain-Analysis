{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, matplotlib, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy import ndimage, misc, stats \n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterdirectory(path,extension):\n",
    "    \"\"\"return every file under the directory given by the path that ends with the extension\"\"\"\n",
    "    files = [file for file in os.listdir(path) if file.lower().endswith(extension) and file[0] !='.']\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirsafe (newpath):\n",
    "    \"\"\"make directory if it doesn't already exist\"\"\"\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unessential\n",
    "class detectionobject:\n",
    "    \n",
    "    def detectlabels (self,array):\n",
    "        \"\"\"returns array where identical pixels are given same label\"\"\"\n",
    "        labeled = measure.label(array)\n",
    "        return labeled\n",
    "    \n",
    "    def detectobjects (self,labels):\n",
    "        \"\"\"returns the minimal parallelepiped that contains all of one label in slices\"\"\"\n",
    "        objects = ndimage.measurements.find_objects(labels)\n",
    "        return objects\n",
    "\n",
    "    def arealist (self,array,objects):\n",
    "        \"\"\"returns list of the sizes of objects in same order\"\"\"\n",
    "        areas = []\n",
    "        [areas.append(array[obj].size) for obj in objects]\n",
    "        return areas\n",
    "    \n",
    "    def __init__(self, array):\n",
    "        \"\"\"creates labels, objects, list of areas, largest area slice, and array largest area\"\"\"\n",
    "        self.labeled = self.detectlabels (array)\n",
    "        self.objects = self.detectobjects(self.labeled)\n",
    "        self.objectareas = self.arealist(array, self.objects)\n",
    "        #== statement returns an boolean array where the only spot that is true is the max area\n",
    "        #[0][0] gets location of max(since its the first/only nonzero) so you get index of object of largest area\n",
    "        self.largestobjectslice = self.objects[np.nonzero(np.array(self.objectareas)== np.array(self.objectareas).max())[0][0]]\n",
    "        #gets actual array values of object slice\n",
    "        self.largestobjectarray = array[self.largestobjectslice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterImage(imagearray):\n",
    "    \"\"\"take a guassian filter of the image to reduce noise then \n",
    "        return a boolean mask noting extremely high values\"\"\"\n",
    "    #the guassian filter is used to reduce noise by blurring/smoothing the image\n",
    "    imagearray = ndimage.filters.gaussian_filter(imagearray,2)\n",
    "    #thresh is a boolean array mirroring the image true if the pixel value is 4.5 std's bigger than the mean\n",
    "    thresh = imagearray>(imagearray.mean() + 4.5*imagearray.std())\n",
    "    #imagearray[np.invert(thresh)] = 0\n",
    "    #imagearray[thresh] = imagearray[thresh]>(imagearray[thresh].mean() + 1.5*imagearray[thresh].std()) \n",
    "    #return  imagearray\n",
    "    if thresh.sum()<30: #if there were only a few numbers over thresh then lower standards\n",
    "        thresh = imagearray>(imagearray.mean() + 3.5*imagearray.std())\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterObjects(labels,lower=20,upper=500):\n",
    "    \"\"\"returns the labels and the objects within the threshold of size\"\"\"\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    selectors=[]\n",
    "    remove_objects =[]\n",
    "    #keep_objects=[]\n",
    "    #selectors = a mask for slices sized between the lower and upper bound\n",
    "    #this is NOT how you use list comprehension, im annoyed\n",
    "    [selectors.append(labels[obj].size>lower and labels[obj].size<upper) for obj in objects]\n",
    "    selectors=np.array(selectors) #turn selectors into nparray\n",
    "    indexer = np.arange(selectors.size) #get two range size of selectors\n",
    "    indexer_inverse = np.arange(selectors.size)\n",
    "    #gets the indexes sized appropriately  \n",
    "    indexer = indexer[selectors];\n",
    "    #gets the indexes not sized appropriately\n",
    "    indexer_inverse = indexer_inverse[np.invert(selectors)];\n",
    "    #remove_objects = all the object slices not size appropriately\n",
    "    [remove_objects.append(objects[o]) for o in indexer_inverse];\n",
    "    #[keep_objects.append(objects[o]) for o in indexer];\n",
    "    #set all the 1s to 0s in the labeled array in the slices sized inappropriately\n",
    "    np.set_printoptions(threshold='nan')\n",
    "    for remv in remove_objects:\n",
    "        labels[remv] =0\n",
    "    #find the objects in the 1-0's,\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    #find the objects that arent none and return it and the labels(returns none when numbered labels missing) \n",
    "    keep_objects = [x for x in objects if x] \n",
    "    return labels,keep_objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unessential\n",
    "def AutoCrop(image, skip=1):\n",
    "    #sum returns the sum of the RGB values and mean averages \n",
    "    #the > returns a boolean array giving true for each entry above the average\n",
    "    Sectionbinary = image.sum(2)>image.sum(2).mean()\n",
    "    #run detection with the boolean array\n",
    "    detectedSection = detectionobject(Sectionbinary)\n",
    "    #this if seems to be some horrible form of attempted cropping and is skipped in the real code\n",
    "    if skip == 0:\n",
    "        if (float(np.array(detectedSection.objectareas).max())/float (np.size(Sectionbinary)))>0.20:\n",
    "            return image[detectedSection.largestobjectslice]\n",
    "        else:\n",
    "            return image\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-43-09d22ff4339a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-09d22ff4339a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \"\"\"Zoom the small array to the size of the large array\"\"\"\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def _zoom2Large (largearray,smallarray):\n",
    "\"\"\"Zoom the small array to the size of the large array\"\"\"\n",
    "        largearrayshape = np.float64(largearray.shape)\n",
    "        smallarrayshape = np.float64 (smallarray.shape)\n",
    "        zoomfactor = (largearrayshape [0]/smallarrayshape[0],largearrayshape[1]/smallarrayshape[1])\n",
    "        zoomfactor = zoomfactor #delete this line\n",
    "        zoomedsmall = ndimage.zoom(smallarray, order=0, zoom = zoomfactor)\n",
    "        return zoomedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allencomparisonarray (sectionnumber, imagearray, Allen_detect_annotation_path='/home/dfpena/Documents/P56_Mouse_annotation/' ):\n",
    "    \"\"\"Read the sectionnumber from the Allen and zoom it to the size of the imagearray\"\"\"\n",
    "    #read the int32 array from the panda\n",
    "    Allendetected = pd.read_pickle(Allen_detect_annotation_path +'Allen_detected_annotation.panda').values[sectionnumber][0]\n",
    "    largeallen = _zoom2Large(imagearray,Allendetected)\n",
    "    return largeallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_images(ipath,iterator,allenlibpath):\n",
    "#     try:    \n",
    "    mkdirsafe('panda')\n",
    "    mkdirsafe('3d')\n",
    "    mkdirsafe('arrays')\n",
    "    #get sectionnumber from number before first _ in name\n",
    "    Sectionnumber = int(ipath.split('_')[0])\n",
    "    #TODO: autocrop actually just equivalent to opening the image rn\n",
    "    image = AutoCrop(ndimage.imread(ipath))\n",
    "    #name and save image\n",
    "    np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'croppedsection',image)\n",
    "    image = filterImage(image[:,:,1]) #could just use grayscale\n",
    "    #name and save mask of high values\n",
    "    np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'filtercroppedsection',image)\n",
    "    labeled = detectionobject(image).labeled #turn boolean mask into numbered mask\n",
    "    labeled, objects = filterObjects(labeled)\n",
    "    #name and save labels within threshold\n",
    "    np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'labels',labeled)\n",
    "    #mkdebug_fig('DebugImages',(str(Sectionnumber)+'_labeledfiltered'),labeled)\n",
    "    Allen = allencomparisonarray(Sectionnumber,image,allenlibpath)\n",
    "    np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'AllenResized',Allen)\n",
    "#         #mkdebug_fig('DebugImages',str(iterator) + '_' +(str(Sectionnumber)+'_Verification'),Allen,0.6)\n",
    "#         cellmap =enumerateRegions(objects,Allen,Sectionnumber,allenlibpath)\n",
    "#         cellmap.to_pickle('panda/'+ str(iterator) + '_' +str(Sectionnumber)+'.panda')\n",
    "#         np.savez('3d/'+str(iterator)+'_'+str(Sectionnumber),objects )\n",
    "#         print(iterator, ipath)\n",
    "#         return (iterator, ipath)\n",
    "#     except ValueError:\n",
    "#         print('No cells could be detected')\n",
    "#         print(iterator, ipath)\n",
    "#         return (iterator, ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['406_593_2_2.jpg', '408_593_2_3.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "path_to_images = 'C:/Users/Student/Desktop/LAB/scans/testbed/'\n",
    "path_to_allenlib = 'C:/Users/Student/Desktop/LAB/Allen/'\n",
    "path_to_figurearray= 'C:/Users/Student/Desktop/LAB/scans/testbed/arrays/'\n",
    "animalname = '18'\n",
    "\n",
    "pd.read_pickle('C:/Users/Student/Desktop/LAB/Allen/Allen_detected_annotation.panda')\n",
    "\n",
    "os.chdir(path_to_images) \n",
    "directory = filterdirectory(os.curdir,\".jpg\")\n",
    "print(directory)\n",
    "\n",
    "i=0\n",
    "for img in directory:\n",
    "    process_images(img, i, path_to_allenlib)\n",
    "    i+=1\n",
    "\n",
    "# mkexcel(path_to_images +'panda', animalname)\n",
    "# mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "# os.chdir(path_to_figurearray)\n",
    "# load_functions_allcores(path_to_figurearray,clients[:])\n",
    "# pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "# output = balanced.map(figure_from_pickle,pickledirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
