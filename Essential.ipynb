{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Counting\n",
    "by David Piena, Waleed, and Jorge Fuentes\n",
    "\n",
    "## Table of contents\n",
    "1. [File Helpers](#file)\n",
    "2. [Cell Counting](#cell)\n",
    "3. [Main Code](#main)\n",
    "4. [Debug Images](#debugImages)\n",
    "5. [Debugging](#debug)\n",
    "6. [Testing](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, matplotlib, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwt, mpld3, xlrd #pandas stuff \n",
    "from skimage import measure\n",
    "from scipy import ndimage, misc, stats \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Helpers <a name=\"file\"></a>\n",
    "These functions build off the os library to navigate the file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterdirectory(path,extension):\n",
    "    \"\"\"return list of files under the directory given by the path that ends with the extension\"\"\"\n",
    "    files = [file for file in os.listdir(path) if file.lower().endswith(extension) and file[0] !='.']\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirsafe (newpath):\n",
    "    \"\"\"make directory if it doesn't already exist\"\"\"\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def useImgDir(path):\n",
    "    \"\"\"switch to img path and create all the needed folders\"\"\"\n",
    "    os.chdir(path)\n",
    "    mkdirsafe('panda')\n",
    "    mkdirsafe('3d')\n",
    "    mkdirsafe('arrays')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    mkdirsafe('DebugImages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Counting <a name=\"cell\"></a>\n",
    "These functions do all the image analysis including object detection and region counting using the Allen Brain Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DetectionObject:\n",
    "    def detectObjects (self, min_size_percent, max_size_percent):\n",
    "        \"\"\"returns the minimal parallelepiped that contains all of one label in slices \n",
    "            within the threshold of size(judged by number of elements)\"\"\"\n",
    "        max_size_percent = .0001\n",
    "        #basically start debugImg at same size of self.labeled\n",
    "        debugImg = np.zeros(self.labeled.shape)\n",
    "        \n",
    "        #find slices for each group of pixels\n",
    "        objects = ndimage.measurements.find_objects(self.labeled)\n",
    "        \n",
    "        #only get objects sized within bounds that exist(returns none when numbered labels missing) \n",
    "        filtered_objects = []\n",
    "        for obj in objects:\n",
    "            if obj:\n",
    "                if self.labeled[obj].size > min_size_percent*self.labeled.size and self.labeled[obj].size < max_size_percent*self.labeled.size:\n",
    "                    filtered_objects.append(obj)\n",
    "                    debugImg[obj] = 255 #make all objects white\n",
    "                else:\n",
    "                    debugImg[obj] = 125 #make all almost objects grey\n",
    "\n",
    "        return filtered_objects, debugImg \n",
    "        \n",
    "    def __init__(self, array, min_size_percent, max_size_percent):\n",
    "        \"\"\"creates labels, objects\"\"\"\n",
    "        #turn boolean mask into \"labeled\" array with unique numbers noting each group/adajecent values\n",
    "        self.labeled, self.num = measure.label(array, return_num=True)\n",
    "        #filtered list of slices bounding objects\n",
    "        self.objects, self.debugImg = self.detectObjects(min_size_percent, max_size_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def brightValues(imagearray, sd_from_mean=4.5):\n",
    "    #thresh is a boolean array mirroring the image true if the pixel value is 4.5 std's bigger than the mean\n",
    "    thresh = imagearray>(imagearray.mean() + sd_from_mean*imagearray.std())\n",
    "    if thresh.sum()<30: #if there were only a few numbers over thresh then lower standards\n",
    "        thresh = imagearray>(imagearray.mean() + sd_from_mean-1*imagearray.std())\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allen Image Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _zoom2Large (largearray,smallarray):\n",
    "    \"\"\"Zoom the small array to the size of the large array\"\"\"\n",
    "    largearrayshape = np.float64(largearray.shape)\n",
    "    smallarrayshape = np.float64 (smallarray.shape)\n",
    "    zoomfactor = (largearrayshape [0]/smallarrayshape[0],largearrayshape[1]/smallarrayshape[1])\n",
    "    zoomedsmall = ndimage.zoom(smallarray, order=0, zoom = zoomfactor)\n",
    "    return zoomedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allencomparisonarray (sectionnumber, imagearray, Allen_detect_annotation_path='/home/dfpena/Documents/P56_Mouse_annotation/' ):\n",
    "    \"\"\"Read the sectionnumber from the Allen and zoom it to the size of the imagearray\"\"\"\n",
    "    #read the int32 array from the panda\n",
    "    Allendetected = pd.read_pickle(Allen_detect_annotation_path +'Allen_detected_annotation.panda').values[sectionnumber][0]\n",
    "    largeallen = _zoom2Large(imagearray,Allendetected)\n",
    "    return largeallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineImages(arr1, arr2, alphaArr2=0.99):\n",
    "    \"\"\"Take two numpy arrays and layers them on top of each other to turn arr1 into red and arr2 into green\"\"\"\n",
    "    #normalize arrays to between 0 and 255\n",
    "    arr1N = arr1/(arr1.max()/255.0)\n",
    "    arr2N = arr2/(arr2.max()/255.0)\n",
    "    combinedImg = np.dstack( ( arr1N, arr2N, np.zeros(arr1.shape) ) ) \n",
    "    return combinedImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterAllenMapby(allenmap,conversionkeyword,startkeyword,identifierIter):\n",
    "    \"\"\"Get the conversionKeyword for the allenmap panda rows where the startkeyword of that row = the identifiers\"\"\"\n",
    "    #allenmap[[s..]].v..==i.. gives a boolean array identifying the allemap rows where the startkeyword = the identifies\n",
    "    #[[s..]] double brackets probably unneccessary \n",
    "    #np.nonzero(...)[0][0] gives the index of the row of the ...\n",
    "    #allenmap[conv...].v...[^] gives the allenmap's conversionkeyword value of ^ index\n",
    "    filtered = [allenmap[conversionkeyword].values[np.nonzero(allenmap[[startkeyword]].values==identifier)[0][0]] for identifier in identifierIter]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatecelllocationarray(structureslist,sectionnumber,Regionnames,parentid,parentname):\n",
    "    \"\"\"Create a pandas dataframe with a row of the section number, structurelist[:,1&2], Regionnames, & parentid\"\"\"\n",
    "    #parentname seems unused\n",
    "    #Side is 0 if left, 1 if right side\n",
    "    cellmap = pd.DataFrame({'SectionNumber': np.array([sectionnumber] * len(structureslist)),\n",
    "                            'StructureID': structureslist[:,1],\n",
    "                            'Side': structureslist[:,2],\n",
    "                            'StructureName': Regionnames,\n",
    "                            'parent_structure_id': parentid,\n",
    "                            \n",
    "                            \n",
    "                           })\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enumerateRegions(objects,ResizedAllen,Sectionnumber,allenpandamappath):\n",
    "    \"\"\"generate a pandas DataFrame recording the info about the objects from the image overlaid on the resized allen\"\"\"\n",
    "    #Get lookup panda datafram with atlas_id,id,name,ontology_id and parent structure \n",
    "    allenmap = pd.read_pickle(allenpandamappath + 'Allen_Lookup.panda')\n",
    "    #recall objects are slices\n",
    "    AllenRegion = []\n",
    "    for obj in objects:\n",
    "        start = obj[1].start\n",
    "        mode = stats.mode(ResizedAllen[obj].flatten())[0][0].astype('int')\n",
    "        myBool = -1\n",
    "        AllenRegion.append([start, mode, myBool])\n",
    "    print(\"Obj\", objects[0], \"Flatten\", ResizedAllen[objects[0]].flatten())\n",
    "    #obj[1].start gets the lowest index of the bounding box for the x/width axis \n",
    "    #stats... takes the mode(probably id naming region) of the object slices from the processing image overlayed on allen([0][0] gives single top mode)\n",
    "    #AllenRegion is composed of a 2D list which each sublist is 3 elements corresponding to the start, mode, and -1         \n",
    "    AllenRegion= np.array(AllenRegion)\n",
    "    #Allen Region = all 3 elements of the list where the mode is greater than 0 and not equal to 8\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] > 0] #TODO: THIS SOMETIMES gets, IndexError: too many indices for array\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] != 8]\n",
    "    #range number of rows left\n",
    "    selector_range = np.arange(AllenRegion.shape[0])\n",
    "    #bool of rows where the object starts in the image below the width/2 \n",
    "    bool_selector =  (AllenRegion[:,0] < ResizedAllen.shape[1]/2)\n",
    "    #set third element(currently -1) of AllenRegion to 0 if object starts in image below the width/2, and 1 otherwise\n",
    "    AllenRegion[selector_range[bool_selector ],2]= 0\n",
    "    AllenRegion[selector_range[np.invert(bool_selector) ],2] = 1\n",
    "    #using the AllenRegions, the variable names are well named\n",
    "    Regionnames = filterAllenMapby(allenmap,'name','id',AllenRegion[:,1])\n",
    "    parentid = filterAllenMapby(allenmap,'parent_structure_id','id',AllenRegion[:,1])\n",
    "    parentname = filterAllenMapby(allenmap,'name','id',parentid)\n",
    "    grandparentid = filterAllenMapby(allenmap,'parent_structure_id','id',parentid)\n",
    "    grandparentname = filterAllenMapby(allenmap,'name','id',grandparentid)\n",
    "    cellmap = generatecelllocationarray(AllenRegion,Sectionnumber,Regionnames,parentid,parentname)\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_images(ipath, iterator, allenlibpath, sd_from_mean=4.5, min_size_percent=.00000003, max_size_percent=.0000009):\n",
    "    \"\"\"\n",
    "    Find objects in the image and overlays the corresponding allen image. Then, create and save panda dataframe.\n",
    "    \n",
    "    :param string ipath: path to image\n",
    "    :param int iterator: unique value for this batch process(start Debug_Images name)\n",
    "    :param string allenlibpath: path to allen library with brains\n",
    "    :param int sd_from_mean: standard deviations above mean that counts as bright\n",
    "    \"\"\"\n",
    "    print(\"Processing \", iterator, ipath)\n",
    "#     try:\n",
    "    #get sectionnumber from number before first _ in name\n",
    "    Sectionnumber = int(ipath.split('_')[0])\n",
    "    image = imageio.imread(ipath)\n",
    "\n",
    "    #get and save brightValues\n",
    "    brightMask = brightValues(image, sd_from_mean)\n",
    "    image[~brightMask] = 0\n",
    "    image[brightMask] = 255\n",
    "    imageio.imwrite('DebugImages/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'brightValues.jpg', image)\n",
    "\n",
    "    #detect 'objects' which means bright Values close by each other within a certain size\n",
    "    detection = DetectionObject(brightMask, min_size_percent, max_size_percent)\n",
    "    labeled, num, objects, debugImg = detection.labeled, detection.num, detection.objects, detection.debugImg\n",
    "    imageio.imwrite('DebugImages/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'detectedObjects.jpg', debugImg)\n",
    "\n",
    "    #name and save allen image corresponding to the sectionnumber zoomed to the size of the image\n",
    "    Allen = allencomparisonarray(Sectionnumber,image,allenlibpath) #allen seems to be grayscale\n",
    "#     imageio.imwrite('DebugImages/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'allen.jpg', Allen)\n",
    "    overlayDebug = combineImages(Allen, debugImg)\n",
    "    imageio.imwrite('DebugImages/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'allenOverlay.jpg', overlayDebug)\n",
    "\n",
    "    #generatecelllocationarray cellmap\n",
    "    cellmap = enumerateRegions(objects, Allen, Sectionnumber, allenlibpath)\n",
    "    #save the objects and cellmap, print and return the iterator and the path to the image\n",
    "    cellmap.to_pickle('panda/'+ str(iterator) + '_' +str(Sectionnumber)+'.panda')\n",
    "    np.savez('3d/'+str(iterator)+'_'+str(Sectionnumber),objects )\n",
    "    return (iterator, ipath)\n",
    "#     except ValueError:\n",
    "#         print('No cells could be detected')\n",
    "#         print(iterator, ipath)\n",
    "#         return (iterator, ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Collect_Pandas(directorylist):\n",
    "    \"\"\"Create single container of all the pickled pandas in the directory\"\"\"\n",
    "    container = pd.DataFrame()\n",
    "    container = container.append([pd.read_pickle(file) for file in directorylist])\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkexcel( path_to_pandas, animalname): #need xls lib\n",
    "    \"\"\"gather all the panda dataframes and create excel sheets and pickles total and for each side\"\"\"\n",
    "    os.chdir(path_to_pandas)\n",
    "    directory = filterdirectory(os.curdir,\".panda\")\n",
    "\n",
    "    #get all the pandas and divide them in the left and right side\n",
    "    Brain = Collect_Pandas(directory)\n",
    "    LateralizedDF = Brain.groupby(['Side'])\n",
    "    LeftDF = LateralizedDF.get_group(0)\n",
    "    RightDF = LateralizedDF.get_group(1)\n",
    "    #count the unique structure names on each side and total \n",
    "    TotalCountsDF = pd.DataFrame({'Cells':Brain.StructureName.value_counts()})\n",
    "    LeftCountsDF = pd.DataFrame({'Cells':LeftDF.StructureName.value_counts()})\n",
    "    RightCountsDF = pd.DataFrame({'Cells':RightDF.StructureName.value_counts()})\n",
    "    \n",
    "    os.chdir('..')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    #Raw\n",
    "    Brain.to_pickle('ExcelSheets/'+animalname +'_total.compile')\n",
    "    Brain.to_excel('ExcelSheets/'+animalname +'_RawTotal.xls')\n",
    "    LeftDF.to_excel ('ExcelSheets/'+animalname +'_RawLeft.xls')\n",
    "    RightDF.to_excel ('ExcelSheets/'+animalname +'_RawRight.xls')\n",
    "\n",
    "    #Compiled\n",
    "    TotalCountsDF.to_excel ('ExcelSheets/'+animalname +'_TotalFreq.xls')\n",
    "    LeftCountsDF.to_excel ('ExcelSheets/'+animalname +'_LeftFreq.xls')\n",
    "    RightCountsDF.to_excel ('ExcelSheets/'+animalname +'_RightFreq.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code<a name=\"main\"></a>\n",
    "Remember your images should have a sectionnumber before '_' to indicate they are part of the same specimen. And the images should already be only green(greyscale green), cropped, and straigtened, see preprocessing to do this automatically.\n",
    "\n",
    "Change the arguments below then run the next few blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change these arguments \n",
    "animalname = '18'\n",
    "path_to_images = \"/Users/jfuentes/Projects/Allen-Brain-Analysis/Images/preprocessed/\" #use the preprocessed folder if you used that code\n",
    "path_to_allenlib = \"/Users/jfuentes/Projects/Allen-Brain-Analysis/Allen/\"\n",
    "sd_from_mean = 4.5 #the number of standard deviations from the mean that cells to be noted are\n",
    "min_size_percent = .00000003 #min size of cells in relation to image size\n",
    "max_size_percent = .0000009 #max size of cells in relation to image size\n",
    "\n",
    "#for command line running in script version\n",
    "if len(sys.argv) == 4:\n",
    "    print(\"Using command line arguments\")\n",
    "    animalname = sys.argv[1]\n",
    "    path_to_images = sys.argv[2]\n",
    "    path_to_allenlib = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['362_593_1_2_ps.jpg', '398_593_1_11.jpg', '370_593_1_4_ps.jpg', '394_593_1_10.jpg', '374_593_1_5.jpg', '382_593_1_7.jpg', '390_593_1_9.jpg', '386_593_1_8.jpg', '406_593_2_1.jpg']\n",
      "Processing  0 362_593_1_2_ps.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/brainLab/lib/python3.6/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float64 to uint8, range [0.0, 255.0]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(506, 513, None), slice(6241, 6258, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 1/9 [00:17<02:23, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  1 398_593_1_11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/brainLab/lib/python3.6/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float64 to uint8, range [0.0, 255.00000000000003]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(495, 503, None), slice(4290, 4342, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [00:28<01:40, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  2 370_593_1_4_ps.jpg\n",
      "(slice(467, 492, None), slice(3281, 3446, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [00:40<01:21, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  3 394_593_1_10.jpg\n",
      "(slice(521, 526, None), slice(3603, 3617, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [00:56<01:10, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  4 374_593_1_5.jpg\n",
      "(slice(861, 865, None), slice(3771, 3776, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [01:11<00:56, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  5 382_593_1_7.jpg\n",
      "(slice(549, 576, None), slice(5984, 6016, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [01:24<00:42, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  6 390_593_1_9.jpg\n",
      "(slice(746, 772, None), slice(3952, 4127, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [01:39<00:28, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  7 386_593_1_8.jpg\n",
      "(slice(645, 651, None), slice(4057, 4070, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [01:53<00:14, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  8 406_593_2_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 9/9 [02:00<00:00, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(386, 388, None), slice(3008, 3010, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_figurearray= path_to_images + 'arrays/'\n",
    "path_to_panda = path_to_images +'panda/'\n",
    "\n",
    "useImgDir(path_to_images)\n",
    "directory = filterdirectory(os.curdir,\".jpg\")\n",
    "print(directory)\n",
    "\n",
    "i=0\n",
    "for img in tqdm(directory):\n",
    "    process_images(img, i, path_to_allenlib, sd_from_mean, min_size_percent, max_size_percent)\n",
    "    i+=1\n",
    "    \n",
    "mkexcel(path_to_panda, animalname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide to Adjustments Using Debug Images<a name=\"debugImages\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each processed image produces the following debugging Images:\n",
    "\n",
    "#### 1) brightValues\n",
    "\n",
    "This highlights in white all the pixels determined to be notably bright. Modify the variable `sd_from_mean` to change which pixels are considered bright. \n",
    "\n",
    "#### 2) detectedObjects\n",
    "\n",
    "Using the bright pixels of the previous step, this picture surrounds in white boxes all groups of cells within the specified bounds. All the gray boxes are bright values that were discarded for not being in the specified bounds. Modify the variables `min_size_percent` and `max_size_percent` to modify the upper and lower bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging<a name=\"debug\"></a>\n",
    "These functions use the premade pandas to make pretty infographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkmpld3figs (path_to_ExcelSheetsfolder,animalname): #need mpld3 and xlrd lib\n",
    "    \"\"\"make a cool html bar graph of excel sheet\"\"\"\n",
    "    import mpld3\n",
    "    from mpld3 import plugins\n",
    "    os.chdir(path_to_ExcelSheetsfolder)\n",
    "    TotalCountsDF = pd.read_excel(animalname+'_TotalFreq.xls')\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(np.arange(TotalCountsDF.size), TotalCountsDF.values)\n",
    "    for i, bar in enumerate(bars.get_children()):\n",
    "        tooltip = mpld3.plugins.LineLabelTooltip(bar, label=str(TotalCountsDF.index[i]))\n",
    "        mpld3.plugins.connect(plt.gcf(), tooltip)\n",
    "    plt.xlim(0,50)\n",
    "    plt.title('Cell Detection for : Subject {0}'.format(animalname))\n",
    "    plt.ylabel('Cell Count')\n",
    "    plt.xlabel('Region number (Scroll over Bar for Region Name)')\n",
    "\n",
    "    a = mpld3.fig_to_html(fig)\n",
    "\n",
    "\n",
    "    Html_file= open(\"{0}.html\".format(animalname),\"w\")\n",
    "    Html_file.write(a)\n",
    "    Html_file.close()\n",
    "    plt.savefig('{0}.svg'.format(animalname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdebug_fig(folder,name,fig, alphav=1):\n",
    "    \"\"\"save fig to folder/name\"\"\"\n",
    "    mkdirsafe(folder)\n",
    "    plt.imshow(fig,alpha=alphav)\n",
    "    plt.savefig(folder+'/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figure_from_pickle(picklepath):\n",
    "    \"\"\"Make a image from all the saved arrays\"\"\"\n",
    "    import gc\n",
    "    #npz's load a dict \n",
    "    figure = np.load(picklepath)['arr_0']\n",
    "    name = picklepath.split('.')\n",
    "    mkdebug_fig('DebugImages',(name[0]),figure)\n",
    "    plt.close()\n",
    "    #cool garbage collection\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def easyRun(animalname, path_to_images, path_to_allenlib):\n",
    "    path_to_figurearray= path_to_images + 'arrays/'\n",
    "\n",
    "    os.chdir(path_to_images) \n",
    "    directory = filterdirectory(os.curdir,\".jpg\")\n",
    "    print(directory)\n",
    "\n",
    "    i=0\n",
    "    for img in directory:\n",
    "        process_images(img, i, path_to_allenlib)\n",
    "        i+=1\n",
    "\n",
    "    #make an excel sheet and html figures\n",
    "    mkexcel(path_to_images +'panda', animalname)\n",
    "    \n",
    "    #beyond here is just figures and debugging stuff\n",
    "    mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "    os.chdir(path_to_figurearray)\n",
    "    pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "    #to debug look at these images\n",
    "    for file in pickledirectory:\n",
    "        figure_from_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "os.chdir(path_to_figurearray)\n",
    "pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "#to debug look at these images\n",
    "for file in pickledirectory:\n",
    "    figure_from_pickle(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING<a name=\"test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 3],\n",
       "       [3, 3, 2],\n",
       "       [2, 2, 2],\n",
       "       [4, 4, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[True, False, True],[True, True, False], [False, False, False], [True, True, True]])\n",
    "detection = DetectionObject(test, 0, 0)\n",
    "x = detection.labeled\n",
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(slice(0, 4, None), slice(0, 3, None))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices = ndimage.measurements.find_objects(test)[0]\n",
    "slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True],\n",
       "       [ True,  True, False],\n",
       "       [False, False, False],\n",
       "       [ True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height, width = 10, 10\n",
    "img = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(labeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3]],\n",
       "\n",
       "       [[4, 4, 4],\n",
       "        [5, 5, 5],\n",
       "        [6, 6, 6]],\n",
       "\n",
       "       [[7, 7, 7],\n",
       "        [8, 8, 8],\n",
       "        [9, 9, 9]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakeImage = np.array([[[1,1,1],[2,2,2],[3,3,3]],[[4,4,4],[5,5,5],[6,6,6]],[[7,7,7],[8,8,8],[9,9,9]]])\n",
    "fakeImage2 = np.array([[[1,9,1],[2,9,2],[3,9,3]],[[4,9,4],[5,9,5],[6,9,6]],[[7,9,7],[8,9,8],[9,9,9]]])\n",
    "fakeImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types:  int64\n",
      "Types:  float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  8.2,  1. ],\n",
       "        [ 2. ,  8.3,  2. ],\n",
       "        [ 3. ,  8.4,  3. ]],\n",
       "\n",
       "       [[ 4. ,  8.5,  4. ],\n",
       "        [ 5. ,  8.6,  5. ],\n",
       "        [ 6. ,  8.7,  6. ]],\n",
       "\n",
       "       [[ 7. ,  8.8,  7. ],\n",
       "        [ 8. ,  8.9,  8. ],\n",
       "        [ 9. ,  9. ,  9. ]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combineImages(fakeImage, fakeImage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brainLab]",
   "language": "python",
   "name": "conda-env-brainLab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
