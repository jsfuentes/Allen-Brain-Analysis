{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, matplotlib, json, gc, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy import ndimage, misc, stats \n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterdirectory(path,extension):\n",
    "    \"\"\"return list of files under the directory given by the path that ends with the extension\"\"\"\n",
    "    files = [file for file in os.listdir(path) if file.lower().endswith(extension) and file[0] !='.']\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirsafe (newpath):\n",
    "    \"\"\"make directory if it doesn't already exist\"\"\"\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class detectionobject:\n",
    "    \n",
    "    def detectlabels (self,array):\n",
    "        \"\"\"returns array where identical pixels are given same label\"\"\"\n",
    "        labeled = measure.label(array)\n",
    "        return labeled\n",
    "    \n",
    "    def detectobjects (self,labels):\n",
    "        \"\"\"returns the minimal parallelepiped that contains all of one label in slices\"\"\"\n",
    "        objects = ndimage.measurements.find_objects(labels)\n",
    "        return objects\n",
    "\n",
    "    def arealist (self,array,objects):\n",
    "        \"\"\"returns list of the sizes of objects in same order\"\"\"\n",
    "        areas = []\n",
    "        [areas.append(array[obj].size) for obj in objects]\n",
    "        return areas\n",
    "    \n",
    "    def __init__(self, array):\n",
    "        \"\"\"creates labels, objects, list of areas, largest area slice, and array largest area\"\"\"\n",
    "        self.labeled = self.detectlabels (array)\n",
    "        self.objects = self.detectobjects(self.labeled)\n",
    "        self.objectareas = self.arealist(array, self.objects)\n",
    "        #== statement returns an boolean array where the only spot that is true is the max area\n",
    "        #[0][0] gets location of max(since its the first/only nonzero) so you get index of object of largest area\n",
    "        self.largestobjectslice = self.objects[np.nonzero(np.array(self.objectareas)== np.array(self.objectareas).max())[0][0]]\n",
    "        #gets actual array values of object slice\n",
    "        self.largestobjectarray = array[self.largestobjectslice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterImage(imagearray):\n",
    "    \"\"\"take a guassian filter of the image to reduce noise then \n",
    "        return a boolean mask noting extremely high values\"\"\"\n",
    "    #the guassian filter is used to reduce noise by blurring/smoothing the image\n",
    "    imagearray = ndimage.filters.gaussian_filter(imagearray,2)\n",
    "    #thresh is a boolean array mirroring the image true if the pixel value is 4.5 std's bigger than the mean\n",
    "    thresh = imagearray>(imagearray.mean() + 4.5*imagearray.std())\n",
    "    #imagearray[np.invert(thresh)] = 0\n",
    "    #imagearray[thresh] = imagearray[thresh]>(imagearray[thresh].mean() + 1.5*imagearray[thresh].std()) \n",
    "    #return  imagearray\n",
    "    if thresh.sum()<30: #if there were only a few numbers over thresh then lower standards\n",
    "        thresh = imagearray>(imagearray.mean() + 3.5*imagearray.std())\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterObjects(labels,lower=20,upper=500):\n",
    "    \"\"\"returns the labels and the objects within the threshold of size\"\"\"\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    selectors=[]\n",
    "    remove_objects =[]\n",
    "    #keep_objects=[]\n",
    "    #selectors = a mask for slices sized between the lower and upper bound\n",
    "    #this is NOT how you use list comprehension, im annoyed\n",
    "    [selectors.append(labels[obj].size>lower and labels[obj].size<upper) for obj in objects]\n",
    "    selectors=np.array(selectors) #turn selectors into nparray\n",
    "    indexer = np.arange(selectors.size) #get two range size of selectors\n",
    "    indexer_inverse = np.arange(selectors.size)\n",
    "    #gets the indexes sized appropriately  \n",
    "    indexer = indexer[selectors];\n",
    "    #gets the indexes not sized appropriately\n",
    "    indexer_inverse = indexer_inverse[np.invert(selectors)];\n",
    "    #remove_objects = all the object slices not size appropriately\n",
    "    [remove_objects.append(objects[o]) for o in indexer_inverse];\n",
    "    #[keep_objects.append(objects[o]) for o in indexer];\n",
    "    #set all the 1s to 0s in the labeled array in the slices sized inappropriately\n",
    "#     np.set_printoptions(threshold='nan')#this line messes up printing should be threshold = nan apparently\n",
    "    for remv in remove_objects:\n",
    "        labels[remv] =0\n",
    "    #find the objects in the 1-0's,\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    #find the objects that arent none and return it and the labels(returns none when numbered labels missing) \n",
    "    keep_objects = [x for x in objects if x] \n",
    "    return labels,keep_objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unessential\n",
    "def AutoCrop(image, skip=1):\n",
    "    #sum returns the sum of the RGB values and mean averages \n",
    "    #the > returns a boolean array giving true for each entry above the average\n",
    "    Sectionbinary = image.sum(2)>image.sum(2).mean()\n",
    "    #run detection with the boolean array\n",
    "    detectedSection = detectionobject(Sectionbinary)\n",
    "    #this if seems to be some horrible form of attempted cropping and is skipped in the real code\n",
    "    if skip == 0:\n",
    "        if (float(np.array(detectedSection.objectareas).max())/float (np.size(Sectionbinary)))>0.20:\n",
    "            return image[detectedSection.largestobjectslice]\n",
    "        else:\n",
    "            return image\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _zoom2Large (largearray,smallarray):\n",
    "    \"\"\"Zoom the small array to the size of the large array\"\"\"\n",
    "    largearrayshape = np.float64(largearray.shape)\n",
    "    smallarrayshape = np.float64 (smallarray.shape)\n",
    "    zoomfactor = (largearrayshape [0]/smallarrayshape[0],largearrayshape[1]/smallarrayshape[1])\n",
    "    zoomfactor = zoomfactor #delete this line\n",
    "    zoomedsmall = ndimage.zoom(smallarray, order=0, zoom = zoomfactor)\n",
    "    return zoomedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allencomparisonarray (sectionnumber, imagearray, Allen_detect_annotation_path='/home/dfpena/Documents/P56_Mouse_annotation/' ):\n",
    "    \"\"\"Read the sectionnumber from the Allen and zoom it to the size of the imagearray\"\"\"\n",
    "    #read the int32 array from the panda\n",
    "    Allendetected = pd.read_pickle(Allen_detect_annotation_path +'Allen_detected_annotation.panda').values[sectionnumber][0]\n",
    "    largeallen = _zoom2Large(imagearray,Allendetected)\n",
    "    return largeallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterAllenMapby(allenmap,conversionkeyword,startkeyword,identifierIter):\n",
    "    \"\"\"Get the conversionKeyword for the allenmap panda rows where the startkeyword of that row = the identifiers\"\"\"\n",
    "    #allenmap[[s..]].v..==i.. gives a boolean array identifying the allemap rows where the startkeyword = the identifies\n",
    "    #[[s..]] double brackets probably unneccessary \n",
    "    #np.nonzero(...)[0][0] gives the index of the row of the ...\n",
    "    #allenmap[conv...].v...[^] gives the allenmap's conversionkeyword value of ^ index\n",
    "    filtered = [allenmap[conversionkeyword].values[np.nonzero(allenmap[[startkeyword]].values==identifier)[0][0]] for identifier in identifierIter]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatecelllocationarray(structureslist,sectionnumber,Regionnames,parentid,parentname):\n",
    "    \"\"\"Create a pandas dataframe with a row of the section number, structurelist[:,1&2], Regionnames, & parentid\"\"\"\n",
    "    #parentname seems unused\n",
    "    #Side is 0 if left, 1 if right side\n",
    "    cellmap = pd.DataFrame({'SectionNumber': np.array([sectionnumber] * len(structureslist)),\n",
    "                            'StructureID': structureslist[:,1],\n",
    "                            'Side': structureslist[:,2],\n",
    "                            'StructureName': Regionnames,\n",
    "                            'parent_structure_id': parentid,\n",
    "                            \n",
    "                            \n",
    "                           })\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enumerateRegions(objects,ResizedAllen,Sectionnumber,allenpandamappath ='/home/dfpena/Documents/P56_Mouse_annotation/P56_Mouse_annotation/'):\n",
    "    \"\"\"generate a pandas DataFrame recording the info about the objects from the image overlaid on the resized allen\"\"\"\n",
    "    allenmap = pd.read_pickle(allenpandamappath + 'Allen_Lookup.panda')\n",
    "    #lookup is a panda dataframe with atlas_id,id,name,ontology_id and parent structure \n",
    "    #recall objects are slices\n",
    "    AllenRegion=[]  \n",
    "    #obj[1].start gets the lowest index of the bounding box for the x/width axis \n",
    "    #stats... takes the mode(probably id naming region) of the object slices from the processing image overlayed on allen([0][0] gives single top mode)\n",
    "    #AllenRegion is composed of a 2D list which each sublist is 3 elements corresponding to the start, mode, and -1 \n",
    "    [AllenRegion.append([obj[1].start,stats.mode(ResizedAllen[obj].flatten())[0][0].astype('int'),-1]) for obj in objects];\n",
    "    AllenRegion= np.array(AllenRegion)\n",
    "    #Allen Region = all 3 elements of the list where the mode is greater than 0 and not equal to 8\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] > 0]\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] != 8]\n",
    "    #range number of rows left\n",
    "    selector_range = np.arange(AllenRegion.shape[0])\n",
    "    #bool of rows where the object starts in the image below the width/2 \n",
    "    bool_selector =  (AllenRegion[:,0] < ResizedAllen.shape[1]/2)\n",
    "    #set third element(currently -1) of AllenRegion to 0 if object starts in image below the width/2, and 1 otherwise\n",
    "    AllenRegion[selector_range[bool_selector ],2]= 0\n",
    "    AllenRegion[selector_range[np.invert(bool_selector) ],2] = 1\n",
    "    #using the AllenRegions, the variable names are well named\n",
    "    Regionnames = filterAllenMapby(allenmap,'name','id',AllenRegion[:,1])\n",
    "    parentid = filterAllenMapby(allenmap,'parent_structure_id','id',AllenRegion[:,1])\n",
    "    parentname = filterAllenMapby(allenmap,'name','id',parentid)\n",
    "    grandparentid = filterAllenMapby(allenmap,'parent_structure_id','id',parentid)\n",
    "    grandparentname = filterAllenMapby(allenmap,'name','id',grandparentid)\n",
    "    cellmap = generatecelllocationarray(AllenRegion,Sectionnumber,Regionnames,parentid,parentname)\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_images(ipath,iterator,allenlibpath):\n",
    "    \"\"\"Find objects in the image and overlays the corresponding allen image\n",
    "        Then, creates and saves a panda dataframe\"\"\"\n",
    "    try:    \n",
    "        mkdirsafe('panda')\n",
    "        mkdirsafe('3d')\n",
    "        mkdirsafe('arrays')\n",
    "        #get sectionnumber from number before first _ in name\n",
    "        Sectionnumber = int(ipath.split('_')[0])\n",
    "        #TODO: autocrop actually just equivalent to opening the image rn\n",
    "        image = AutoCrop(ndimage.imread(ipath))\n",
    "        #name and save image\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'croppedsection',image)\n",
    "        image = filterImage(image[:,:,1]) #could just use grayscale\n",
    "        #name and save mask of high values\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'filtercroppedsection',image)\n",
    "        labeled = detectionobject(image).labeled #turn boolean mask into numbered mask\n",
    "        labeled, objects = filterObjects(labeled)\n",
    "        #name and save labels within threshold\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'labels',labeled)\n",
    "        #mkdebug_fig('DebugImages',(str(Sectionnumber)+'_labeledfiltered'),labeled)\n",
    "        #name and save allen image corresponding to the sectionnumber zoomed to the size of the image\n",
    "        Allen = allencomparisonarray(Sectionnumber,image,allenlibpath) #allen seems to be grayscale \n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'AllenResized',Allen)\n",
    "            #mkdebug_fig('DebugImages',str(iterator) + '_' +(str(Sectionnumber)+'_Verification'),Allen,0.6)\n",
    "        #generatecelllocationarray cellmap\n",
    "        cellmap =enumerateRegions(objects,Allen,Sectionnumber,allenlibpath)\n",
    "        #save the objects and cellmap, print and return the iterator and the path to the image\n",
    "        cellmap.to_pickle('panda/'+ str(iterator) + '_' +str(Sectionnumber)+'.panda')\n",
    "        np.savez('3d/'+str(iterator)+'_'+str(Sectionnumber),objects )\n",
    "        print(iterator, ipath)\n",
    "        return (iterator, ipath)\n",
    "    except ValueError:\n",
    "        print('No cells could be detected')\n",
    "        print(iterator, ipath)\n",
    "        return (iterator, ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Collect_Pandas(directorylist):\n",
    "    \"\"\"Create single container of all the pickled pandas in the directory\"\"\"\n",
    "    container = pd.DataFrame()\n",
    "    container = container.append([pd.read_pickle(file) for file in directorylist])\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkexcel( path_to_pandas, animalname): #need xls lib\n",
    "    \"\"\"gather all the panda dataframes and create excel sheets and pickles total and for each side\"\"\"\n",
    "    os.chdir(path_to_pandas)\n",
    "    directory = filterdirectory(os.curdir,\".panda\")\n",
    "\n",
    "    #get all the pandas and divide them in the left and right side\n",
    "    Brain = Collect_Pandas(directory)\n",
    "    LateralizedDF = Brain.groupby(['Side'])\n",
    "    LeftDF = LateralizedDF.get_group(0)\n",
    "    RightDF = LateralizedDF.get_group(1)\n",
    "    #count the unique structure names on each side and total \n",
    "    TotalCountsDF = pd.DataFrame({'Cells':Brain.StructureName.value_counts()})\n",
    "    LeftCountsDF = pd.DataFrame({'Cells':LeftDF.StructureName.value_counts()})\n",
    "    RightCountsDF = pd.DataFrame({'Cells':RightDF.StructureName.value_counts()})\n",
    "    \n",
    "    os.chdir('..')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    #Raw\n",
    "    Brain.to_pickle('ExcelSheets/'+animalname +'_total.compile')\n",
    "    Brain.to_excel('ExcelSheets/'+animalname +'_RawTotal.xls')\n",
    "    LeftDF.to_excel ('ExcelSheets/'+animalname +'_RawLeft.xls')\n",
    "    RightDF.to_excel ('ExcelSheets/'+animalname +'_RawRight.xls')\n",
    "\n",
    "    #Compiled\n",
    "    TotalCountsDF.to_excel ('ExcelSheets/'+animalname +'_TotalFreq.xls')\n",
    "    LeftCountsDF.to_excel ('ExcelSheets/'+animalname +'_LeftFreq.xls')\n",
    "    RightCountsDF.to_excel ('ExcelSheets/'+animalname +'_RightFreq.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkmpld3figs (path_to_ExcelSheetsfolder,animalname): #need mpld3 and xlrd lib\n",
    "    \"\"\"make a cool html bar graph of excel sheet\"\"\"\n",
    "    import mpld3\n",
    "    from mpld3 import plugins\n",
    "    os.chdir(path_to_ExcelSheetsfolder)\n",
    "    TotalCountsDF = pd.read_excel(animalname+'_TotalFreq.xls')\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(np.arange(TotalCountsDF.size),TotalCountsDF.values)\n",
    "    for i, bar in enumerate(bars.get_children()):\n",
    "        tooltip = mpld3.plugins.LineLabelTooltip(bar, label=str(TotalCountsDF.index[i]))\n",
    "        mpld3.plugins.connect(plt.gcf(), tooltip)\n",
    "    plt.xlim(0,50)\n",
    "    plt.title('Cell Detection for : Subject {0}'.format(animalname))\n",
    "    plt.ylabel('Cell Count')\n",
    "    plt.xlabel('Region number (Scroll over Bar for Region Name)')\n",
    "\n",
    "    a = mpld3.fig_to_html(fig)\n",
    "\n",
    "\n",
    "    Html_file= open(\"{0}.html\".format(animalname),\"w\")\n",
    "    Html_file.write(a)\n",
    "    Html_file.close()\n",
    "    plt.savefig('{0}.svg'.format(animalname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdebug_fig(folder,name,fig, alphav=1):\n",
    "    \"\"\"save fig to folder/name\"\"\"\n",
    "    mkdirsafe(folder)\n",
    "    plt.imshow(fig,alpha=alphav)\n",
    "    plt.savefig(folder+'/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figure_from_pickle(picklepath):\n",
    "    \"\"\"Make a image from all the saved arrays\"\"\"\n",
    "    #npz's load a dict \n",
    "    figure = np.load(picklepath)['arr_0']\n",
    "    name = picklepath.split('.')\n",
    "    mkdebug_fig('DebugImages',(name[0]),figure)\n",
    "    plt.close()\n",
    "    #cool garbage collection\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def easyRun(animalname, path_to_images, path_to_allenlib):\n",
    "    path_to_figurearray= path_to_images + 'arrays/'\n",
    "\n",
    "    os.chdir(path_to_images) \n",
    "    directory = filterdirectory(os.curdir,\".jpg\")\n",
    "    print(directory)\n",
    "\n",
    "    i=0\n",
    "    for img in directory:\n",
    "        process_images(img, i, path_to_allenlib)\n",
    "        i+=1\n",
    "\n",
    "    #make an excel sheet and html figures\n",
    "    mkexcel(path_to_images +'panda', animalname)\n",
    "    #beyond here is just figures and debugging stuff\n",
    "    mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "    os.chdir(path_to_figurearray)\n",
    "    pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "    #to debug look at these images\n",
    "    for file in pickledirectory:\n",
    "        figure_from_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['406_593_2_2.jpg', '408_593_2_3.jpg']\n",
      "0 406_593_2_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 408_593_2_3.jpg\n"
     ]
    }
   ],
   "source": [
    "#change these arguments \n",
    "animalname = '18'\n",
    "path_to_images = 'C:/Users/Student/Desktop/LAB/scans/testbed/'\n",
    "path_to_allenlib = 'C:/Users/Student/Desktop/LAB/Allen/'\n",
    "#for command line running in script version\n",
    "if len(sys.argv) == 4:\n",
    "    print(\"Using command line arguments\")\n",
    "    animalname = sys.argv[1]\n",
    "    path_to_images = sys.argv[2]\n",
    "    path_to_allenlib = sys.argv[3]\n",
    "    \n",
    "easyRun(animalname, path_to_images, path_to_allenlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
