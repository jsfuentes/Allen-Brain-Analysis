{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Counting\n",
    "by David Piena, Waleed, and Jorge Fuentes\n",
    "\n",
    "## Table of contents\n",
    "1. [File Helpers](#file)\n",
    "2. [Cell Counting](#cell)\n",
    "3. [Main Code](#main)\n",
    "4. [Debugging](#debug)\n",
    "5. [Testing](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, matplotlib, json, gc, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwt, mpld3, xlrd #pandas stuff \n",
    "from skimage import measure\n",
    "from scipy import ndimage, misc, stats \n",
    "from tqdm import tqdm\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Helpers <a name=\"file\"></a>\n",
    "These functions build off the os library to navigate the file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterdirectory(path,extension):\n",
    "    \"\"\"return list of files under the directory given by the path that ends with the extension\"\"\"\n",
    "    files = [file for file in os.listdir(path) if file.lower().endswith(extension) and file[0] !='.']\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdirsafe (newpath):\n",
    "    \"\"\"make directory if it doesn't already exist\"\"\"\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useImgDir(path):\n",
    "    \"\"\"switch to img path and create all the needed folders\"\"\"\n",
    "    os.chdir(path)\n",
    "    mkdirsafe('panda')\n",
    "    mkdirsafe('3d')\n",
    "    mkdirsafe('arrays')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    mkdirsafe('DebugImages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Counting <a name=\"cell\"></a>\n",
    "These functions do all the image analysis including object detection and region counting using the Allen Brain Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detectionobject:\n",
    "    def detectlabels (self,array):\n",
    "        \"\"\"returns array where identical pixels are given same label\"\"\"\n",
    "        labeled, num = measure.label(array, return_num=True)\n",
    "#         print(\"NUM\", num)\n",
    "        return labeled\n",
    "    \n",
    "    def detectobjects (self,labels):\n",
    "        \"\"\"returns the minimal parallelepiped that contains all of one label in slices\"\"\"\n",
    "        objects = ndimage.measurements.find_objects(labels)\n",
    "        return objects\n",
    "\n",
    "    def arealist (self,array,objects):\n",
    "        \"\"\"returns list of the sizes of objects in same order\"\"\"\n",
    "        areas = []\n",
    "        [areas.append(array[obj].size) for obj in objects]\n",
    "        return areas\n",
    "    \n",
    "    def __init__(self, array):\n",
    "        \"\"\"creates labels, objects, list of areas, largest area slice, and array largest area\"\"\"\n",
    "        self.labeled = self.detectlabels (array)\n",
    "        self.objects = self.detectobjects(self.labeled)\n",
    "        self.objectareas = self.arealist(array, self.objects)\n",
    "        #== statement returns an boolean array where the only spot that is true is the max area\n",
    "        #[0][0] gets location of max(since its the first/only nonzero) so you get index of object of largest area\n",
    "        self.largestobjectslice = self.objects[np.nonzero(np.array(self.objectareas)== np.array(self.objectareas).max())[0][0]]\n",
    "        #gets actual array values of object slice\n",
    "        self.largestobjectarray = array[self.largestobjectslice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    " def brightValues(imagearray, sd_from_mean=4.5):\n",
    "    #thresh is a boolean array mirroring the image true if the pixel value is 4.5 std's bigger than the mean\n",
    "    thresh = imagearray>(imagearray.mean() + sd_from_mean*imagearray.std())\n",
    "    if thresh.sum()<30: #if there were only a few numbers over thresh then lower standards\n",
    "        thresh = imagearray>(imagearray.mean() + sd_from_mean-1*imagearray.std())\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterObjects(labels, min_size_percent, max_size_percent):\n",
    "    \"\"\"returns the labels and the objects within the threshold of size(judged by number of elements)\"\"\"\n",
    "    \n",
    "    #find slices for each group of pixels\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    \n",
    "    #only get objects sized within bounds that exist(returns none when numbered labels missing) \n",
    "    filtered_objects = []\n",
    "    for obj in objects:\n",
    "        if obj:\n",
    "            if labels[obj].size > min_size_percent*labels.size and labels[obj].size < max_size_percent*labels.size:\n",
    "                filtered_objects.append(obj)\n",
    "    \n",
    "    #np.set_printoptions(threshold='nan')#this line messes up printing should be threshold = nan apparently\n",
    "    #FIND THE SIGNIFICANCE OF MAKING ALL THE NON OBJECTS NOW 0 \n",
    "    return labels, filtered_objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zoom2Large (largearray,smallarray):\n",
    "    \"\"\"Zoom the small array to the size of the large array\"\"\"\n",
    "    largearrayshape = np.float64(largearray.shape)\n",
    "    smallarrayshape = np.float64 (smallarray.shape)\n",
    "    zoomfactor = (largearrayshape [0]/smallarrayshape[0],largearrayshape[1]/smallarrayshape[1])\n",
    "    zoomfactor = zoomfactor #delete this line\n",
    "    zoomedsmall = ndimage.zoom(smallarray, order=0, zoom = zoomfactor)\n",
    "    return zoomedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allencomparisonarray (sectionnumber, imagearray, Allen_detect_annotation_path='/home/dfpena/Documents/P56_Mouse_annotation/' ):\n",
    "    \"\"\"Read the sectionnumber from the Allen and zoom it to the size of the imagearray\"\"\"\n",
    "    #read the int32 array from the panda\n",
    "    Allendetected = pd.read_pickle(Allen_detect_annotation_path +'Allen_detected_annotation.panda').values[sectionnumber][0]\n",
    "    largeallen = _zoom2Large(imagearray,Allendetected)\n",
    "    return largeallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterAllenMapby(allenmap,conversionkeyword,startkeyword,identifierIter):\n",
    "    \"\"\"Get the conversionKeyword for the allenmap panda rows where the startkeyword of that row = the identifiers\"\"\"\n",
    "    #allenmap[[s..]].v..==i.. gives a boolean array identifying the allemap rows where the startkeyword = the identifies\n",
    "    #[[s..]] double brackets probably unneccessary \n",
    "    #np.nonzero(...)[0][0] gives the index of the row of the ...\n",
    "    #allenmap[conv...].v...[^] gives the allenmap's conversionkeyword value of ^ index\n",
    "    filtered = [allenmap[conversionkeyword].values[np.nonzero(allenmap[[startkeyword]].values==identifier)[0][0]] for identifier in identifierIter]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatecelllocationarray(structureslist,sectionnumber,Regionnames,parentid,parentname):\n",
    "    \"\"\"Create a pandas dataframe with a row of the section number, structurelist[:,1&2], Regionnames, & parentid\"\"\"\n",
    "    #parentname seems unused\n",
    "    #Side is 0 if left, 1 if right side\n",
    "    cellmap = pd.DataFrame({'SectionNumber': np.array([sectionnumber] * len(structureslist)),\n",
    "                            'StructureID': structureslist[:,1],\n",
    "                            'Side': structureslist[:,2],\n",
    "                            'StructureName': Regionnames,\n",
    "                            'parent_structure_id': parentid,\n",
    "                            \n",
    "                            \n",
    "                           })\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerateRegions(objects,ResizedAllen,Sectionnumber,allenpandamappath ='/home/dfpena/Documents/P56_Mouse_annotation/P56_Mouse_annotation/'):\n",
    "    \"\"\"generate a pandas DataFrame recording the info about the objects from the image overlaid on the resized allen\"\"\"\n",
    "    allenmap = pd.read_pickle(allenpandamappath + 'Allen_Lookup.panda')\n",
    "    #lookup is a panda dataframe with atlas_id,id,name,ontology_id and parent structure \n",
    "    #recall objects are slices\n",
    "    AllenRegion=[]  \n",
    "    #obj[1].start gets the lowest index of the bounding box for the x/width axis \n",
    "    #stats... takes the mode(probably id naming region) of the object slices from the processing image overlayed on allen([0][0] gives single top mode)\n",
    "    #AllenRegion is composed of a 2D list which each sublist is 3 elements corresponding to the start, mode, and -1 \n",
    "    [AllenRegion.append([obj[1].start,stats.mode(ResizedAllen[obj].flatten())[0][0].astype('int'),-1]) for obj in objects];\n",
    "    AllenRegion= np.array(AllenRegion)\n",
    "    #Allen Region = all 3 elements of the list where the mode is greater than 0 and not equal to 8\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] > 0]\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] != 8]\n",
    "    #range number of rows left\n",
    "    selector_range = np.arange(AllenRegion.shape[0])\n",
    "    #bool of rows where the object starts in the image below the width/2 \n",
    "    bool_selector =  (AllenRegion[:,0] < ResizedAllen.shape[1]/2)\n",
    "    #set third element(currently -1) of AllenRegion to 0 if object starts in image below the width/2, and 1 otherwise\n",
    "    AllenRegion[selector_range[bool_selector ],2]= 0\n",
    "    AllenRegion[selector_range[np.invert(bool_selector) ],2] = 1\n",
    "    #using the AllenRegions, the variable names are well named\n",
    "    Regionnames = filterAllenMapby(allenmap,'name','id',AllenRegion[:,1])\n",
    "    parentid = filterAllenMapby(allenmap,'parent_structure_id','id',AllenRegion[:,1])\n",
    "    parentname = filterAllenMapby(allenmap,'name','id',parentid)\n",
    "    grandparentid = filterAllenMapby(allenmap,'parent_structure_id','id',parentid)\n",
    "    grandparentname = filterAllenMapby(allenmap,'name','id',grandparentid)\n",
    "    cellmap = generatecelllocationarray(AllenRegion,Sectionnumber,Regionnames,parentid,parentname)\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(ipath, iterator, allenlibpath, sd_from_mean=4.5, min_size_percent=.00000003, max_size_percent=.0000009):\n",
    "    \"\"\"\n",
    "    Find objects in the image and overlays the corresponding allen image. Then, create and save panda dataframe.\n",
    "    \n",
    "    :param string ipath: path to image\n",
    "    :param int iterator: unique value for this batch process(start Debug_Images name)\n",
    "    :param string allenlibpath: path to allen library with brains\n",
    "    :param int sd_from_mean: standard deviations above mean that counts as bright\n",
    "    \"\"\"\n",
    "    print(\"Processing \", iterator, ipath)\n",
    "    try:\n",
    "        #get sectionnumber from number before first _ in name\n",
    "        Sectionnumber = int(ipath.split('_')[0])\n",
    "        image = imageio.imread(ipath)\n",
    "\n",
    "        #get and save brightValues\n",
    "        brightMask = brightValues(image, sd_from_mean)\n",
    "        image[~brightMask] = 0\n",
    "        image[brightMask] = 255\n",
    "        imageio.imwrite('DebugImages/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'brightValues.jpg', image)\n",
    "\n",
    "        #turn boolean mask into \"labeled\" array with unique numbers noting each group/adajecent values\n",
    "        labeled = detectionobject(brightMask).labeled \n",
    "\n",
    "        #TODO: Actually use detection object for this intermidate steps, add lower and upper dependent on percent of size\n",
    "        #get objects(tuples of slices indicating rows and columns (start, exclusive end) for all objects)\n",
    "        labeled, objects = filterObjects(labeled, min_size_percent, max_size_percent)\n",
    "\n",
    "        #TODO: Save debug image of labeled, maybe by randomizing the colors\n",
    "\n",
    "        #name and save allen image corresponding to the sectionnumber zoomed to the size of the image\n",
    "        Allen = allencomparisonarray(Sectionnumber,image,allenlibpath) #allen seems to be grayscale \n",
    "        #TODO: Save debug image\n",
    "\n",
    "        #generatecelllocationarray cellmap\n",
    "        cellmap =enumerateRegions(objects,Allen,Sectionnumber,allenlibpath)\n",
    "        #save the objects and cellmap, print and return the iterator and the path to the image\n",
    "        cellmap.to_pickle('panda/'+ str(iterator) + '_' +str(Sectionnumber)+'.panda')\n",
    "        np.savez('3d/'+str(iterator)+'_'+str(Sectionnumber),objects )\n",
    "        return (iterator, ipath)\n",
    "    except ValueError:\n",
    "        print('No cells could be detected')\n",
    "        print(iterator, ipath)\n",
    "        return (iterator, ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collect_Pandas(directorylist):\n",
    "    \"\"\"Create single container of all the pickled pandas in the directory\"\"\"\n",
    "    container = pd.DataFrame()\n",
    "    container = container.append([pd.read_pickle(file) for file in directorylist])\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkexcel( path_to_pandas, animalname): #need xls lib\n",
    "    \"\"\"gather all the panda dataframes and create excel sheets and pickles total and for each side\"\"\"\n",
    "    os.chdir(path_to_pandas)\n",
    "    directory = filterdirectory(os.curdir,\".panda\")\n",
    "\n",
    "    #get all the pandas and divide them in the left and right side\n",
    "    Brain = Collect_Pandas(directory)\n",
    "    LateralizedDF = Brain.groupby(['Side'])\n",
    "    LeftDF = LateralizedDF.get_group(0)\n",
    "    RightDF = LateralizedDF.get_group(1)\n",
    "    #count the unique structure names on each side and total \n",
    "    TotalCountsDF = pd.DataFrame({'Cells':Brain.StructureName.value_counts()})\n",
    "    LeftCountsDF = pd.DataFrame({'Cells':LeftDF.StructureName.value_counts()})\n",
    "    RightCountsDF = pd.DataFrame({'Cells':RightDF.StructureName.value_counts()})\n",
    "    \n",
    "    os.chdir('..')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    #Raw\n",
    "    Brain.to_pickle('ExcelSheets/'+animalname +'_total.compile')\n",
    "    Brain.to_excel('ExcelSheets/'+animalname +'_RawTotal.xls')\n",
    "    LeftDF.to_excel ('ExcelSheets/'+animalname +'_RawLeft.xls')\n",
    "    RightDF.to_excel ('ExcelSheets/'+animalname +'_RawRight.xls')\n",
    "\n",
    "    #Compiled\n",
    "    TotalCountsDF.to_excel ('ExcelSheets/'+animalname +'_TotalFreq.xls')\n",
    "    LeftCountsDF.to_excel ('ExcelSheets/'+animalname +'_LeftFreq.xls')\n",
    "    RightCountsDF.to_excel ('ExcelSheets/'+animalname +'_RightFreq.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code<a name=\"main\"></a>\n",
    "Remember your images should have a sectionnumber before '_' to indicate they are part of the same specimen. And the images should already be only green(greyscale green), cropped, and straigtened, see preprocessing to do this automatically.\n",
    "\n",
    "Change the arguments below then run the next few blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change these arguments \n",
    "animalname = '18'\n",
    "path_to_images = \"/Users/jfuentes/Projects/Allen-Brain-Analysis/Images/preprocessed/\"\n",
    "path_to_allenlib = \"/Users/jfuentes/Projects/Allen-Brain-Analysis/Allen/\"\n",
    "sd_from_mean = 4.5 #the number of standard deviations from the mean that cells to be noted are\n",
    "min_size_percent = .00000003 #min size of cells in relation to image size\n",
    "max_size_percent = .0000009 #max size of cells in relation to image size\n",
    "\n",
    "#for command line running in script version\n",
    "if len(sys.argv) == 4:\n",
    "    print(\"Using command line arguments\")\n",
    "    animalname = sys.argv[1]\n",
    "    path_to_images = sys.argv[2]\n",
    "    path_to_allenlib = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['362_593_1_2_ps.jpg', '398_593_1_11.jpg', '370_593_1_4_ps.jpg', '394_593_1_10.jpg', '374_593_1_5.jpg', '382_593_1_7.jpg', '390_593_1_9.jpg', '386_593_1_8.jpg', '406_593_2_1.jpg']\n",
      "Processing  0 362_593_1_2_ps.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 1/9 [00:04<00:35,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  1 398_593_1_11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [00:07<00:27,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  2 370_593_1_4_ps.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [00:11<00:22,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  3 394_593_1_10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [00:15<00:19,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  4 374_593_1_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [00:19<00:15,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  5 382_593_1_7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [00:23<00:11,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  6 390_593_1_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [00:27<00:07,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  7 386_593_1_8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [00:31<00:03,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  8 406_593_2_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:33<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "path_to_figurearray= path_to_images + 'arrays/'\n",
    "path_to_panda = path_to_images +'panda/'\n",
    "\n",
    "useImgDir(path_to_images)\n",
    "directory = filterdirectory(os.curdir,\".jpg\")\n",
    "print(directory)\n",
    "\n",
    "i=0\n",
    "for img in tqdm(directory):\n",
    "    process_images(img, i, path_to_allenlib, sd_from_mean, min_size_percent, max_size_percent)\n",
    "    i+=1\n",
    "    \n",
    "mkexcel(path_to_panda, animalname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging<a name=\"debug\"></a>\n",
    "These functions use the premade pandas to make pretty infographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkmpld3figs (path_to_ExcelSheetsfolder,animalname): #need mpld3 and xlrd lib\n",
    "    \"\"\"make a cool html bar graph of excel sheet\"\"\"\n",
    "    import mpld3\n",
    "    from mpld3 import plugins\n",
    "    os.chdir(path_to_ExcelSheetsfolder)\n",
    "    TotalCountsDF = pd.read_excel(animalname+'_TotalFreq.xls')\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(np.arange(TotalCountsDF.size), TotalCountsDF.values)\n",
    "    for i, bar in enumerate(bars.get_children()):\n",
    "        tooltip = mpld3.plugins.LineLabelTooltip(bar, label=str(TotalCountsDF.index[i]))\n",
    "        mpld3.plugins.connect(plt.gcf(), tooltip)\n",
    "    plt.xlim(0,50)\n",
    "    plt.title('Cell Detection for : Subject {0}'.format(animalname))\n",
    "    plt.ylabel('Cell Count')\n",
    "    plt.xlabel('Region number (Scroll over Bar for Region Name)')\n",
    "\n",
    "    a = mpld3.fig_to_html(fig)\n",
    "\n",
    "\n",
    "    Html_file= open(\"{0}.html\".format(animalname),\"w\")\n",
    "    Html_file.write(a)\n",
    "    Html_file.close()\n",
    "    plt.savefig('{0}.svg'.format(animalname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdebug_fig(folder,name,fig, alphav=1):\n",
    "    \"\"\"save fig to folder/name\"\"\"\n",
    "    mkdirsafe(folder)\n",
    "    plt.imshow(fig,alpha=alphav)\n",
    "    plt.savefig(folder+'/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_from_pickle(picklepath):\n",
    "    \"\"\"Make a image from all the saved arrays\"\"\"\n",
    "    #npz's load a dict \n",
    "    figure = np.load(picklepath)['arr_0']\n",
    "    name = picklepath.split('.')\n",
    "    mkdebug_fig('DebugImages',(name[0]),figure)\n",
    "    plt.close()\n",
    "    #cool garbage collection\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyRun(animalname, path_to_images, path_to_allenlib):\n",
    "    path_to_figurearray= path_to_images + 'arrays/'\n",
    "\n",
    "    os.chdir(path_to_images) \n",
    "    directory = filterdirectory(os.curdir,\".jpg\")\n",
    "    print(directory)\n",
    "\n",
    "    i=0\n",
    "    for img in directory:\n",
    "        process_images(img, i, path_to_allenlib)\n",
    "        i+=1\n",
    "\n",
    "    #make an excel sheet and html figures\n",
    "    mkexcel(path_to_images +'panda', animalname)\n",
    "    \n",
    "    #beyond here is just figures and debugging stuff\n",
    "    mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "    os.chdir(path_to_figurearray)\n",
    "    pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "    #to debug look at these images\n",
    "    for file in pickledirectory:\n",
    "        figure_from_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "os.chdir(path_to_figurearray)\n",
    "pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "#to debug look at these images\n",
    "for file in pickledirectory:\n",
    "    figure_from_pickle(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING<a name=\"test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[True, False, True],[True, True, False], [False, False, False], [True, True, True]])\n",
    "detectionobject(test).labeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
