{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\IPython\\parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Client",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\IPython\\utils\\shimmodule.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimport_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\IPython\\utils\\importstring.py\u001b[0m in \u001b[0;36mimport_item\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipyparallel'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4915ffc2d59c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W:/ipcontroller-client.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# use synchronous computations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\student\\anaconda2\\envs\\pp3\\lib\\site-packages\\IPython\\utils\\shimmodule.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimport_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Client"
     ]
    }
   ],
   "source": [
    "from IPython import parallel\n",
    "clients = parallel.Client('W:/ipcontroller-client.json')\n",
    "clients.block = True  # use synchronous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%px import os, matplotlib, json, gc\n",
    "%px matplotlib.use('Agg')\n",
    "%px import numpy as np\n",
    "%px import pandas as pd\n",
    "%px import matplotlib.pyplot as plt\n",
    "%px from skimage import measure\n",
    "%px from scipy import ndimage , misc, stats\n",
    "%px matplotlib.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, matplotlib, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy import ndimage , misc, stats\n",
    "matplotlib.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Collect_Pandas(directorylist):\n",
    "    container = pd.DataFrame()\n",
    "    container = container.append([pd.read_pickle(file) for file in directorylist])\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatefigures(directory,name):\n",
    "    total_panda = Collect_Directory_Pandas(directory)\n",
    "    total_panda.to_excel(name)\n",
    "    total_panda\n",
    "    mpld3.fig_to_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterObjectsdebug(labels,lower=20,upper=500):\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    selectors=[]\n",
    "    remove_objects =[]\n",
    "    keep_objects=[]\n",
    "    [selectors.append(labels[obj].size>lower and labels[obj].size<upper) for obj in objects]\n",
    "    selectors=np.array(selectors)\n",
    "    indexer = np.arange(selectors.size)\n",
    "    indexer_inverse = np.arange(selectors.size)\n",
    "    indexer = indexer[selectors];\n",
    "    indexer_inverse = indexer_inverse[np.invert(selectors)];\n",
    "    [remove_objects.append(objects[o]) for o in indexer_inverse];\n",
    "    [keep_objects.append(objects[o]) for o in indexer];\n",
    "    for remv in remove_objects:\n",
    "        labels[remv] =0\n",
    "    \n",
    "    return labels,keep_objects,remove_objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def filterObjects(labels,lower=20,upper=500):\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    selectors=[]\n",
    "    remove_objects =[]\n",
    "    #keep_objects=[]\n",
    "    [selectors.append(labels[obj].size>lower and labels[obj].size<upper) for obj in objects]\n",
    "    selectors=np.array(selectors)\n",
    "    indexer = np.arange(selectors.size)\n",
    "    indexer_inverse = np.arange(selectors.size)\n",
    "    indexer = indexer[selectors];\n",
    "    indexer_inverse = indexer_inverse[np.invert(selectors)];\n",
    "    [remove_objects.append(objects[o]) for o in indexer_inverse];\n",
    "    #[keep_objects.append(objects[o]) for o in indexer];\n",
    "    for remv in remove_objects:\n",
    "        labels[remv] =0\n",
    "    objects = ndimage.measurements.find_objects(labels)\n",
    "    keep_objects = [x for x in objects if x] \n",
    "    \n",
    "    return labels,keep_objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class detectionobject:\n",
    "    \n",
    "    def detectlabels (self,array):\n",
    "        labeled = measure.label(array)\n",
    "        return labeled\n",
    "    \n",
    "    def detectobjects (self,labels):\n",
    "        objects = ndimage.measurements.find_objects(labels)\n",
    "        return objects\n",
    "\n",
    "    def arealist (self,array,objects):\n",
    "        areas = []\n",
    "        [areas.append(array[obj].size) for obj in objects]\n",
    "        return areas\n",
    "    def __init__(self, array):\n",
    "        self.labeled = self.detectlabels (array)\n",
    "        self.objects = self.detectobjects(self.labeled)\n",
    "        self.objectareas = self.arealist(array, self.objects)\n",
    "        self.largestobjectslice = self.objects[np.nonzero(np.array(self.objectareas)== np.array(self.objectareas).max())[0][0]]\n",
    "        self.largestobjectarray = array[self.largestobjectslice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Paul_Allen_Atlas_object:\n",
    "    \n",
    "    def loadallen(self, rawfile,dtype = np.int32,size = (528,320,456)):\n",
    "        with open(rawfile, 'rb') as fid:\n",
    "            data_array = np.fromfile(fid, dtype)\n",
    "        data_array = data_array.reshape(size, order=\"F\")\n",
    "        return data_array\n",
    "   \n",
    "        \n",
    "    def __init__(self,path):\n",
    "        self.ANO = self.loadallen(path)\n",
    "        self.ANO_Threshold = self.ANO>0\n",
    "        self.ANO_CenterMerge = np.copy(self.ANO_Threshold)\n",
    "        \n",
    "        Merge = self.ANO_Threshold [:,:,80:230].mean(2).transpose() * np.ones_like (self.ANO_Threshold[:,:,80:230]).transpose()\n",
    "        self.ANO_CenterMerge[:,:,80:230] = Merge.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to identify ROI names\n",
    "\n",
    "def build_structure(data, d=[]):\n",
    "    if 'children' in data:\n",
    "        for c in data['children']:\n",
    "            d.append({'atlas_id': c.get('atlas_id' ),'name': c.get('name', None), 'id': c.get('id'),'ontology_id': c.get('ontology_id'),'parent_structure_id': c.get('parent_structure_id')})\n",
    "            build_structure(c, d)\n",
    "    return d\n",
    "\n",
    "def identifystructure(labelnum,level = 0):  \n",
    "    jdata = json.loads(open ('C:/Users/dfpena/Documents/Python/structures.json').read())\n",
    "    u = build_structure(jdata['msg'][0])\n",
    "    for dic in u:\n",
    "        if dic['id']==labelnum:\n",
    "            struc = dic \n",
    "    return struc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_all_Allen_threshold(path):\n",
    "    allen = Paul_Allen_Atlas_object('C:/Users/dfpena/Documents/P56_Mouse_annotation/annotation.raw')\n",
    "    thresh = allen.ANO_Threshold\n",
    "    merged = allen.ANO_CenterMerge\n",
    "    del allen\n",
    "    c = []\n",
    "    [c.append(thresh[x,:,:][detectionobject(merged[x,:,:]).largestobjectslice]) for x in np.arange(merged.shape[0])];\n",
    "    del thresh\n",
    "    del merged\n",
    "    return pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_all_Allen_slices(path = 'C:/Users/dfpena/Documents/P56_Mouse_annotation/annotation.raw'):\n",
    "    allen = Paul_Allen_Atlas_object(path)\n",
    "    thresh = allen.ANO_Threshold\n",
    "    merged = allen.ANO_CenterMerge\n",
    "    del allen\n",
    "    c = []\n",
    "    [c.append(detectionobject(merged[x,:,:]).largestobjectslice) for x in np.arange(merged.shape[0])];\n",
    "    del thresh\n",
    "    del merged\n",
    "    return pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_all_Allen_annotation(path = 'C:/Users/dfpena/Documents/P56_Mouse_annotation/annotation.raw'):\n",
    "    allen = Paul_Allen_Atlas_object(path)\n",
    "    ANO = allen.ANO\n",
    "    thresh = allen.ANO_Threshold\n",
    "    merged = allen.ANO_CenterMerge\n",
    "    del allen\n",
    "    c = []\n",
    "    [c.append(ANO[x,:,:][detectionobject(merged[x,:,:]).largestobjectslice]) for x in np.arange(merged.shape[0])];\n",
    "    del thresh\n",
    "    del merged\n",
    "    return pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _zoom2Large (largearray,smallarray):\n",
    "        largearrayshape = np.float64(largearray.shape)\n",
    "        smallarrayshape = np.float64 (smallarray.shape)\n",
    "        zoomfactor = (largearrayshape [0]/smallarrayshape[0],largearrayshape[1]/smallarrayshape[1])\n",
    "        zoomfactor = zoomfactor\n",
    "        zoomedsmall = ndimage.zoom(smallarray, order=0, zoom = zoomfactor)\n",
    "        return zoomedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allencomparisonarray (sectionnumber, imagearray, Allen_detect_annotation_path='/home/dfpena/Documents/P56_Mouse_annotation/' ):\n",
    "    Allendetected = pd.read_pickle(Allen_detect_annotation_path +'Allen_detected_annotation.panda').values[sectionnumber][0]\n",
    "    largeallen = _zoom2Large(imagearray,Allendetected)\n",
    "    return largeallen\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AutoCrop(image, skip=1):\n",
    "    Sectionbinary = image.sum(2)>image.sum(2).mean()\n",
    "    detectedSection = detectionobject(Sectionbinary)\n",
    "    if skip == 0:\n",
    "        if (float(np.array(detectedSection.objectareas).max())/float (np.size(Sectionbinary)))>0.20:\n",
    "            return image[detectedSection.largestobjectslice]\n",
    "        else:\n",
    "            return image\n",
    "    else:\n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatecelllocationarray(structureslist,sectionnumber,Regionnames,parentid,parentname):\n",
    "    cellmap = pd.DataFrame({'SectionNumber': np.array([sectionnumber] * len(structureslist)),\n",
    "                            'StructureID': structureslist[:,1],\n",
    "                            'Side': structureslist[:,2],\n",
    "                            'StructureName': Regionnames,\n",
    "                            'parent_structure_id': parentid,\n",
    "                            \n",
    "                            \n",
    "                           })\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterImage(imagearray):\n",
    "    imagearray = ndimage.filters.gaussian_filter(imagearray,2)\n",
    "    thresh = imagearray>(imagearray.mean() + 4.5*imagearray.std())\n",
    "    #imagearray[np.invert(thresh)] = 0\n",
    "    #imagearray[thresh] = imagearray[thresh]>(imagearray[thresh].mean() + 1.5*imagearray[thresh].std()) \n",
    "    #return  imagearray\n",
    "    if thresh.sum()<30:\n",
    "        thresh = imagearray>(imagearray.mean() + 3.5*imagearray.std()) \n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterAllenMapbySingle(allenmap,conversionkeyword,startkeyword,identifier):\n",
    "    filtered = allenmap[conversionkeyword].va\\0lues[np.nonzero(allenmap[[startkeyword]].values==identifier)[0]]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterAllenMapby(allenmap,conversionkeyword,startkeyword,identifierIter):\n",
    "    filtered = [allenmap[conversionkeyword].values[np.nonzero(allenmap[[startkeyword]].values==identifier)[0][0]] for identifier in identifierIter]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enumerateRegions(objects,ResizedAllen,Sectionnumber,allenpandamappath ='/home/dfpena/Documents/P56_Mouse_annotation/P56_Mouse_annotation/'):\n",
    "    allenmap = pd.read_pickle(allenpandamappath + 'Allen_Lookup.panda')\n",
    "    AllenRegion=[]\n",
    "    [AllenRegion.append([obj[1].start,stats.mode(ResizedAllen[obj].flatten())[0][0].astype('int'),-1]) for obj in objects];\n",
    "    AllenRegion= np.array(AllenRegion)\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] > 0]\n",
    "    AllenRegion= AllenRegion[AllenRegion[:,1] != 8]\n",
    "    selector_range = np.arange(AllenRegion.shape[0])\n",
    "    bool_selector =  (AllenRegion[:,0] < ResizedAllen.shape[1]/2) \n",
    "    AllenRegion[selector_range[bool_selector ],2]= 0\n",
    "    AllenRegion[selector_range[np.invert(bool_selector) ],2] = 1\n",
    "    Regionnames = filterAllenMapby(allenmap,'name','id',AllenRegion[:,1])\n",
    "    parentid = filterAllenMapby(allenmap,'parent_structure_id','id',AllenRegion[:,1])\n",
    "    parentname = filterAllenMapby(allenmap,'name','id',parentid)\n",
    "    grandparentid = filterAllenMapby(allenmap,'parent_structure_id','id',parentid)\n",
    "    grandparentname = filterAllenMapby(allenmap,'name','id',grandparentid)\n",
    "    cellmap = generatecelllocationarray(AllenRegion,Sectionnumber,Regionnames,parentid,parentname)\n",
    "    return cellmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterdirectory(path,extension):\n",
    "    directory= [file for file in os.listdir(path) if file.lower().endswith(extension) and file[0] !='.']\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirsafe (newpath):\n",
    "    if not os.path.exists(newpath): os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdebug_fig(folder,name,fig, alphav=1):\n",
    "    mkdirsafe(folder)\n",
    "    plt.imshow(fig,alpha=alphav)\n",
    "    plt.savefig(folder+'/'+name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_images(ipath,iterator,allenlibpath):\n",
    "    try:    \n",
    "        mkdirsafe('panda')\n",
    "        mkdirsafe('3d')\n",
    "        mkdirsafe('arrays')\n",
    "        Sectionnumber = int(ipath.split('_')[0])\n",
    "        image = AutoCrop(ndimage.imread(ipath))\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'croppedsection',image)\n",
    "        image = filterImage(image[:,:,1])\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'filtercroppedsection',image)\n",
    "        labeled = detectionobject(image).labeled\n",
    "        labeled, objects = filterObjects(labeled)\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+ 'labels',labeled)\n",
    "        #mkdebug_fig('DebugImages',(str(Sectionnumber)+'_labeledfiltered'),labeled)\n",
    "        Allen = allencomparisonarray(Sectionnumber,image,allenlibpath)\n",
    "        np.savez('arrays/'+str(iterator)+'_'+str(Sectionnumber)+'_'+'AllenResized',Allen)\n",
    "        #mkdebug_fig('DebugImages',str(iterator) + '_' +(str(Sectionnumber)+'_Verification'),Allen,0.6)\n",
    "        cellmap =enumerateRegions(objects,Allen,Sectionnumber,allenlibpath)\n",
    "        cellmap.to_pickle('panda/'+ str(iterator) + '_' +str(Sectionnumber)+'.panda')\n",
    "        np.savez('3d/'+str(iterator)+'_'+str(Sectionnumber),objects )\n",
    "        print(iterator, ipath)\n",
    "        return (iterator, ipath)\n",
    "    except ValueError:\n",
    "        print('No cells could be detected')\n",
    "        print(iterator, ipath)\n",
    "        return (iterator, ipath)\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_functions_allcores(path, dcview):\n",
    "    dcview['mkdirsafe'] =mkdirsafe\n",
    "    dcview['mkdebug_fig'] =mkdebug_fig\n",
    "    dcview['AutoCrop'] = AutoCrop\n",
    "    dcview['detectionobject'] = detectionobject\n",
    "    dcview['filterImage'] = filterImage\n",
    "    dcview['filterObjects'] = filterObjects\n",
    "    dcview['allencomparisonarray'] = allencomparisonarray\n",
    "    dcview['_zoom2Large'] = _zoom2Large\n",
    "    dcview['enumerateRegions'] = enumerateRegions\n",
    "    dcview['filterAllenMapby'] = filterAllenMapby\n",
    "    dcview['generatecelllocationarray'] = generatecelllocationarray\n",
    "    dcview[\"os.chdir('{}') \".format(path)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Process_images_SuperCluster(view, imagelist,imagenumberarray,path_to_allenlib='W:/Allen/'):\n",
    "    \"\"\"create a list of arguments for process images and distribute to cores\"\"\"\n",
    "    path_to_allenlib_iterator = []\n",
    "    [path_to_allenlib_iterator.append(path_to_allenlib) for i in np.arange(np.size(imagelist))]\n",
    "    return view.map(process_images,imagelist,imagenumberarray,path_to_allenlib_iterator)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figure_from_pickle(picklepath):\n",
    "    figure = np.load(picklepath)['arr_0']\n",
    "    name = picklepath.split('.')\n",
    "    mkdebug_fig('DebugImages',(name[0]),figure)\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkexcel( path_to_pandas, animalname):\n",
    "    os.chdir(path_to_pandas)\n",
    "    directory = filterdirectory(os.curdir,\".panda\")\n",
    "\n",
    "    Brain = Collect_Pandas(directory)\n",
    "    LateralizedDF = Brain.groupby(['Side'])\n",
    "    LeftDF = LateralizedDF.get_group(0)\n",
    "    RightDF = LateralizedDF.get_group(1)\n",
    "\n",
    "\n",
    "    TotalCountsDF = pd.DataFrame({'Cells':Brain.StructureName.value_counts()})\n",
    "    LeftCountsDF = pd.DataFrame({'Cells':LeftDF.StructureName.value_counts()})\n",
    "    RightCountsDF = pd.DataFrame({'Cells':RightDF.StructureName.value_counts()})\n",
    "\n",
    "\n",
    "    os.chdir('..')\n",
    "    mkdirsafe('ExcelSheets')\n",
    "    #Raw\n",
    "    Brain.to_pickle('ExcelSheets/'+animalname +'_total.compile')\n",
    "    Brain.to_excel('ExcelSheets/'+animalname +'_RawTotal.xls')\n",
    "    LeftDF.to_excel ('ExcelSheets/'+animalname +'_RawLeft.xls')\n",
    "    RightDF.to_excel ('ExcelSheets/'+animalname +'_RawRight.xls')\n",
    "\n",
    "\n",
    "\n",
    "    #Compiled\n",
    "    TotalCountsDF.to_excel ('ExcelSheets/'+animalname +'_TotalFreq.xls')\n",
    "    LeftCountsDF.to_excel ('ExcelSheets/'+animalname +'_LeftFreq.xls')\n",
    "    RightCountsDF.to_excel ('ExcelSheets/'+animalname +'_RightFreq.xls')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkmpld3figs (path_to_ExcelSheetsfolder,animalname):\n",
    "    import mpld3\n",
    "    from mpld3 import plugins\n",
    "    os.chdir(path_to_ExcelSheetsfolder)\n",
    "    TotalCountsDF = pd.read_excel(animalname+'_TotalFreq.xls')\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    bars = plt.bar(np.arange(TotalCountsDF.size),TotalCountsDF.values)\n",
    "    for i, bar in enumerate(bars.get_children()):\n",
    "        tooltip = mpld3.plugins.LineLabelTooltip(bar, label=str(TotalCountsDF.index[i]))\n",
    "        mpld3.plugins.connect(plt.gcf(), tooltip)\n",
    "    plt.xlim(0,50)\n",
    "    plt.title('Cell Detection for : Subject {0}'.format(animalname))\n",
    "    plt.ylabel('Cell Count')\n",
    "    plt.xlabel('Region number (Scroll over Bar for Region Name)')\n",
    "\n",
    "    a = mpld3.fig_to_html(fig)\n",
    "\n",
    "\n",
    "    Html_file= open(\"{0}.html\".format(animalname),\"w\")\n",
    "    Html_file.write(a)\n",
    "    Html_file.close()\n",
    "    plt.savefig('{0}.svg'.format(animalname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mke_all_directories(path):\n",
    "    os.chdir(path)\n",
    "    mkdirsafe('panda')\n",
    "    mkdirsafe('3d')\n",
    "    mkdirsafe('arrays')\n",
    "    mkdirsafe('ExcelSheets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EasyRun_process_folder_images_Supercluster_balanced(animalname,path_to_images,allenlib,clients):\n",
    "    if path_to_images[-1] ==\"/\":\n",
    "        path_to_figurearray = path_to_images + \"arrays/\"\n",
    "    else:\n",
    "        path_to_figurearray = path_to_images + \"/arrays/\"\n",
    "        \n",
    "    mke_all_directories(path_to_images)\n",
    "    os.chdir(path_to_images)\n",
    "    \n",
    "    directory = filterdirectory(os.curdir,\".jpg\")\n",
    "    load_functions_allcores(folder,clients[:])\n",
    "    balanced = clients.load_balanced_view()\n",
    "    Process_images_SuperCluster(balanced,directory,np.arange(np.size(directory)))\n",
    "    mkexcel(path_to_images + 'panada', animalname)\n",
    "    mkmpld3figs (path_to_images + 'ExcelSheets', animalname)\n",
    "    \n",
    "    os.chdir(path_to_figurearray)\n",
    "    load_functions_allcores(path_to_figurearray,clients[:])\n",
    "    pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "    output= balanced.map(figure_from_pickle, pickledirectory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkedebugfigsParallel(path_to_figurearray, clients):\n",
    "    balanced = clients.load_balanced_view()\n",
    "    os.chdir(path_to_figurearray)\n",
    "    load_functions_allcores(path_to_figurearray,clients[:])\n",
    "    pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "    output = balanced.map(figure_from_pickle,pickledirectory)\n",
    "    return output\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Determine_missing_panda(imagepath,pandapath,filters =['.jpg','.panda']):\n",
    "    a = filterdirectory(imagepath,filters[0])\n",
    "    b = filterdirectory(pandapath,filters[1])\n",
    "    imagenumbersarray = [i.split(\"_\")[0] for i in a]\n",
    "    pandacompleted = [i.split(\"_\")[1].split('.')[0] for i in b]\n",
    "    return list(set(imagenumbersarray) -set(pandacompleted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regenerateruntimelist (missingpandaslist,firstrundirectorylist):\n",
    "    directoryframe = pd.DataFrame([i.split('_') for i in firstrundirectorylist])\n",
    "    indexlist = [directoryframe.loc[directoryframe[0]==i].index.get_values()[0] for i in missingpandaslist]\n",
    "    return indexlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RetryErrorImages (imagepath,allenlib):\n",
    "    os.chdir(imagepath)\n",
    "    pandapath = imagepath +'panda/'\n",
    "    a = Determine_missing_panda(imagepath,pandapath)\n",
    "    b = filterdirectory(imagepath,'.jpg')\n",
    "    c = regenerateruntimelist(a,b)\n",
    "    out = [process_images(b[i],i,path_to_allenlib) for i in c]\n",
    "    return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPICAL RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_images = 'W:/Confirmed Images/D1D2 Chronic Pain/D2/18_fixed/'\n",
    "path_to_allenlib = 'W:/Allen/'\n",
    "path_to_figurearray= 'W:/Confirmed Images/D1D2 Chronic Pain/D2/18_fixed/arrays'\n",
    "animalname = '18'\n",
    "\n",
    "os.chdir(path_to_images) \n",
    "directory = filterdirectory(os.curdir,\".jpg\")\n",
    "\n",
    "load_functions_allcores(path_to_images,clients[:])\n",
    "balanced = clients.load_balanced_view()\n",
    "\n",
    "Process_images_SuperCluster(balanced, directory,np.arange(np.size(directory)))\n",
    "\n",
    "mkexcel(path_to_images +'panda', animalname)\n",
    "mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "os.chdir(path_to_figurearray)\n",
    "load_functions_allcores(path_to_figurearray,clients[:])\n",
    "pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "output = balanced.map(figure_from_pickle,pickledirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_images = 'W:/Confirmed Images/D1D2 Chronic Pain/D2/CPT5 11 Cuff/'\n",
    "path_to_allenlib = 'W:/Allen/'\n",
    "path_to_figurearray= 'W:/Confirmed Images/D1D2 Chronic Pain/D2/CPT5 11 Cuff/arrays'\n",
    "animalname = '11'\n",
    "\n",
    "os.chdir(path_to_images) \n",
    "directory = filterdirectory(os.curdir,\".jpg\")\n",
    "\n",
    "load_functions_allcores(path_to_images,clients[:])\n",
    "balanced = clients.load_balanced_view()\n",
    "\n",
    "Process_images_SuperCluster(balanced, directory,np.arange(np.size(directory)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mkexcel(path_to_images +'panda', animalname)\n",
    "mkmpld3figs(path_to_images +'ExcelSheets',animalname)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(path_to_figurearray)\n",
    "load_functions_allcores(path_to_figurearray,clients[:])\n",
    "pickledirectory = filterdirectory(os.curdir,\".npz\")\n",
    "output = balanced.map(figure_from_pickle,pickledirectory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
